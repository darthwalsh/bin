#!/usr/bin/env uv run
"""Transcribe a stereo WAV file with speaker labels (left=Me, right=You).
#ai-slop generated by Cursor

Currently supports only Apple Silicon. Recommendations for others:
- Windows + GTX 1060: Best option for cost/performance. Use faster-whisper with int8 quantization.
- Linux cloud CPU-only: Only if you can accept lower accuracy (tiny/base models) or very long wait times.
- Linux cloud GPU: Only if you need cloud processing and can afford GPU instances (~$0.50+/hour).
"""

# /// script
# dependencies = [
#     "mlx-whisper",
# ]
# ///

import argparse
import logging
import shutil
import subprocess
import sys
import tempfile
from dataclasses import dataclass
from pathlib import Path

import mlx_whisper

logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)

# Config
SPEAKER_LEFT = "Me"
SPEAKER_RIGHT = "You"

# If you get "Repository Not Found / Please make sure you specified the correct..." you have a typo in the model name
WHISPER_MODEL = "mlx-community/whisper-large-v3-mlx"


@dataclass(frozen=True)
class Segment:
  """A transcribed segment with timing and speaker info."""

  start: float
  end: float
  text: str
  speaker: str = ""


def split_stereo(input_wav: Path, temp_dir: Path) -> tuple[Path, Path]:
  """Split stereo WAV into left and right channels using ffmpeg."""
  left_wav = temp_dir / "left.wav"
  right_wav = temp_dir / "right.wav"

  # Extract left channel (first channel)
  subprocess.run(
    [
      "ffmpeg",
      "-y",
      "-i",
      str(input_wav),
      "-filter_complex",
      "channelsplit=channel_layout=stereo[left][right]",
      "-map",
      "[left]",
      str(left_wav),
      "-map",
      "[right]",
      str(right_wav),
    ],
    check=True,
    capture_output=True,
  )
  logger.info("Split stereo into %s and %s", left_wav.name, right_wav.name)
  return left_wav, right_wav


def transcribe_audio(audio_path: Path, speaker: str) -> list[Segment]:
  """Transcribe audio file using mlx-whisper and return segments."""
  logger.info("Transcribing %s...", audio_path.name)
  result = mlx_whisper.transcribe(
    str(audio_path),
    path_or_hf_repo=WHISPER_MODEL,
    language="en",
    word_timestamps=True,
    verbose=False,
    # Prevent hallucination loops
    condition_on_previous_text=False,  # Don't let previous output influence next segment
    compression_ratio_threshold=2.4,  # Skip segments with repetitive text
    no_speech_threshold=0.6,  # Skip silent segments
    logprob_threshold=-1.0,  # Skip low-confidence outputs (default -1.0)
    hallucination_silence_threshold=2.0,  # Skip if >2s trailing silence detected
  )

  segments = []
  for seg in result.get("segments", []):
    start = float(seg.get("start", 0.0))
    end = float(seg.get("end", start))
    text = seg.get("text", "").strip()
    segments.append(Segment(start=start, end=end, text=text, speaker=speaker))

  logger.info("Got %d segments from %s", len(segments), audio_path.name)
  return segments


def main() -> None:
  parser = argparse.ArgumentParser(description="Transcribe stereo WAV with speaker labels")
  parser.add_argument("input_wav", type=Path, help="Input stereo WAV file")
  args = parser.parse_args()

  input_wav: Path = args.input_wav
  if not input_wav.exists():
    logger.error("Input file not found: %s", input_wav)
    sys.exit(1)

  output_path = input_wav.with_suffix(".md")

  # Create temp directory for intermediate files
  temp_dir = Path(tempfile.mkdtemp(prefix="stereo_transcribe_"))
  try:
    # Split stereo into channels
    left_wav, right_wav = split_stereo(input_wav, temp_dir)

    # Transcribe both channels with speaker labels
    left_segments = transcribe_audio(left_wav, speaker=SPEAKER_LEFT)
    right_segments = transcribe_audio(right_wav, speaker=SPEAKER_RIGHT)

    # Merge and sort by time
    combined = sorted(left_segments + right_segments, key=lambda s: s.start)

    # Write transcript with timestamps: [MM:SS] Speaker: Text
    # Me: gets two spaces, You: gets one space after colon
    out_lines = []
    for seg in combined:
      text = seg.text.strip()
      minutes = int(seg.start // 60)
      seconds = int(seg.start % 60)
      timestamp = f"[{minutes:02d}:{seconds:02d}]"

      # Me: gets two spaces, You: gets one space
      if seg.speaker == SPEAKER_LEFT:
        line = f"{timestamp} {seg.speaker}:  {text}"
      else:
        line = f"{timestamp} {seg.speaker}: {text}"
      out_lines.append(line)

    output_path.write_text("\n".join(out_lines))
    logger.info("Wrote %d lines to %s", len(out_lines), output_path)

  finally:
    # Cleanup temp directory
    shutil.rmtree(temp_dir, ignore_errors=True)
    logger.info("Cleaned up temp files")


if __name__ == "__main__":
  main()
