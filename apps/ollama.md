
- [x] Tried to run https://ollama.com/library/llama3.3 on macbook and that did not work
https://www.llama.com/docs/llama-everywhere/running-meta-llama-on-mac/
- [x] Tried something smaller ?3.2 ?2 and that seemed to work better
- [ ] Try running model that only needs 4-8GB? need other RAM
- [ ] Try https://github.com/JerryZLiu/Dayflow app using Local LLM, but requires 16GB rRAM?

