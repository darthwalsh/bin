After reading Daniel Kahneman's *Thinking Fast and Slow* one idea I came to on 2024-06-02:
>AIs are like System One thinking, and are often wrong but come up with any associative facts

- Was thinking, could you repeatedly trigger System One thinking, and "simulate" System Two thinking step-by-step?
- This made me thing of [[Explang]] with associative lookup
- Now it's very interesting to see OpenAI o1, with Chain of Though

## System 1 vs. System 2 explained
The name are terrible (like Type 1 vs Type 2 errors in medical tests...)
https://thedecisionlab.com/reference-guide/philosophy/system-1-and-system-2-thinking
>**System 1** is fast, automatic, and intuitive, operating with little to no effort. This mode of thinking allows us to make quick decisions and judgments based on patterns and experiences.
>**System 2** is slow, deliberate, and conscious, requiring intentional effort. This type of thinking is used for complex problem-solving and analytical tasks where more thought and consideration are necessary.

Also, Veritasium's [The Science of Thinking](https://www.youtube.com/watch?v=UBVV8pch1dM) is a great video explainer